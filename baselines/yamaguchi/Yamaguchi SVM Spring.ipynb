{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff87a2fe",
   "metadata": {},
   "source": [
    "## Group Spring Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6d3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8549aa",
   "metadata": {},
   "source": [
    "# Group Spring Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d67689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m__pycache__\u001b[m\u001b[m\r\n",
      "datainfo_static_5.npy\r\n",
      "edges_all_test_group_static_5.npy\r\n",
      "edges_all_valid_group_static_5.npy\r\n",
      "edges_sampled_all_test_group_static_5.npy\r\n",
      "edges_sampled_all_train_group_static_5.npy\r\n",
      "edges_sampled_all_valid_group_static_5.npy\r\n",
      "ga_test_group_static_5.npy\r\n",
      "ga_train_group_static_5.npy\r\n",
      "ga_valid_group_static_5.npy\r\n",
      "generate_dataset.py\r\n",
      "generate_dataset_group.py\r\n",
      "gr_test_group_static_5.npy\r\n",
      "gr_train_group_static_5.npy\r\n",
      "gr_valid_group_static_5.npy\r\n",
      "loc_all_test_group_static_5.npy\r\n",
      "loc_all_valid_group_static_5.npy\r\n",
      "loc_sampled_all_test_group_static_5.npy\r\n",
      "loc_sampled_all_train_group_static_20.npy\r\n",
      "loc_sampled_all_train_group_static_5.npy\r\n",
      "loc_sampled_all_valid_group_static_5.npy\r\n",
      "sampled_indices_all_test_group_static_5.npy\r\n",
      "sampled_indices_all_train_group_static_5.npy\r\n",
      "sampled_indices_all_valid_group_static_5.npy\r\n",
      "spring_sim.py\r\n",
      "spring_sim_group.py\r\n",
      "test_data_loader_static_5.pth\r\n",
      "train_data_loader_static_5.pth\r\n",
      "valid_data_loader_static_5.pth\r\n",
      "vel_all_test_group_static_5.npy\r\n",
      "vel_all_valid_group_static_5.npy\r\n",
      "vel_sampled_all_test_group_static_5.npy\r\n",
      "vel_sampled_all_train_group_static_20.npy\r\n",
      "vel_sampled_all_train_group_static_5.npy\r\n",
      "vel_sampled_all_valid_group_static_5.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/simulation/spring_simulation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc29e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6469404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "data_folder = \"data/simulation/spring_simulation/\"\n",
    "suffix = \"_static_5\"\n",
    "\n",
    "loc_train = np.load('data/simulation/spring_simulation/loc_sampled_all_train_group' + suffix + '.npy')\n",
    "vel_train = np.load('data/simulation/spring_simulation/vel_sampled_all_train_group' + suffix + '.npy')\n",
    "edges_train = np.load('data/simulation/spring_simulation/gr_train_group' + suffix + '.npy')\n",
    "\n",
    "loc_valid = np.load('data/simulation/spring_simulation/loc_sampled_all_valid_group' + suffix + '.npy')\n",
    "vel_valid = np.load('data/simulation/spring_simulation/vel_sampled_all_valid_group' + suffix + '.npy')\n",
    "edges_valid = np.load('data/simulation/spring_simulation/gr_valid_group' + suffix + '.npy')\n",
    "\n",
    "loc_test = np.load('data/simulation/spring_simulation/loc_sampled_all_test_group' + suffix + '.npy')\n",
    "vel_test = np.load('data/simulation/spring_simulation/vel_sampled_all_test_group' + suffix + '.npy')\n",
    "edges_test = np.load('data/simulation/spring_simulation/gr_test_group' + suffix + '.npy')\n",
    "\n",
    "num_atoms = loc_train.shape[3]\n",
    "\n",
    "# Reshape to: [num_sims, num_atoms, num_timesteps, num_dims]\n",
    "loc_train = np.transpose(loc_train, [0, 3, 1, 2])\n",
    "vel_train = np.transpose(vel_train, [0, 3, 1, 2])\n",
    "feat_train = np.concatenate([loc_train, vel_train], axis=3)\n",
    "edges_train = np.reshape(edges_train, [-1, num_atoms ** 2])\n",
    "edges_train = np.array((edges_train + 1) / 2, dtype=np.int64)\n",
    "\n",
    "loc_valid = np.transpose(loc_valid, [0, 3, 1, 2])\n",
    "vel_valid = np.transpose(vel_valid, [0, 3, 1, 2])\n",
    "feat_valid = np.concatenate([loc_valid, vel_valid], axis=3)\n",
    "edges_valid = np.reshape(edges_valid, [-1, num_atoms ** 2])\n",
    "edges_valid = np.array((edges_valid + 1) / 2, dtype=np.int64)\n",
    "\n",
    "loc_test = np.transpose(loc_test, [0, 3, 1, 2])\n",
    "vel_test = np.transpose(vel_test, [0, 3, 1, 2])\n",
    "feat_test = np.concatenate([loc_test, vel_test], axis=3)\n",
    "edges_test = np.reshape(edges_test, [-1, num_atoms ** 2])\n",
    "edges_test = np.array((edges_test + 1) / 2, dtype=np.int64)\n",
    "\n",
    "\n",
    "# Exclude self edges\n",
    "off_diag_idx = np.ravel_multi_index(\n",
    "    np.where(np.ones((num_atoms, num_atoms)) - np.eye(num_atoms)),\n",
    "    [num_atoms, num_atoms])\n",
    "edges_train = edges_train[:, off_diag_idx]\n",
    "edges_valid = edges_valid[:, off_diag_idx]\n",
    "edges_test = edges_test[:, off_diag_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90441877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create edge-node relation\n",
    "\n",
    "num_nodes = feat_train.shape[1]\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "\n",
    "def create_edgeNode_relation(num_nodes, self_loops=False):\n",
    "    if self_loops:\n",
    "        indices = np.ones([num_nodes, num_nodes])\n",
    "    else:\n",
    "        indices = np.ones([num_nodes, num_nodes]) - np.eye(num_nodes)\n",
    "    rel_rec = np.array(encode_onehot(np.where(indices)[0]), dtype=np.float32)\n",
    "    rel_send = np.array(encode_onehot(np.where(indices)[1]), dtype=np.float32)\n",
    "    \n",
    "    return rel_rec, rel_send \n",
    "\n",
    "rel_rec, rel_send = create_edgeNode_relation(num_nodes, self_loops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1167f84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 5, 49, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e740dfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f3948",
   "metadata": {},
   "source": [
    "## Feature Engineering on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf501f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4f29af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 5, 196)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_train_re = feat_train.reshape((feat_train.shape[0], feat_train.shape[1],-1))\n",
    "feat_train_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748e596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "senders_train = np.matmul(rel_send, feat_train_re)\n",
    "receivers_train = np.matmul(rel_rec, feat_train_re)\n",
    "senders_train = senders_train.reshape((senders_train.shape[0], senders_train.shape[1],feat_train.shape[2],feat_train.shape[-1]))\n",
    "receivers_train = receivers_train.reshape((receivers_train.shape[0],receivers_train.shape[1],feat_train.shape[2],feat_train.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0cc8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 20, 49, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Edge shape: [batch_size, n_edges, n_timesteps, n_features]\n",
    "senders_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb18350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract velocities and locations\n",
    "velocity_senders_train = senders_train[:,:,:,2:]\n",
    "velocity_receivers_train = receivers_train[:,:,:,2:]\n",
    "location_senders_train = senders_train[:,:,:,:2]\n",
    "location_receivers_train = receivers_train[:,:,:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62aa3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Normalized distance histogram\n",
    "distance_train = location_senders_train-location_receivers_train\n",
    "distance_train = distance_train**2\n",
    "distance_train = distance_train.sum(-1)\n",
    "distance_train = np.sqrt(distance_train)\n",
    "distance_train = distance_train.reshape((-1, distance_train.shape[-1]))\n",
    "distance_train_max = distance_train.max()\n",
    "distance_train_min = distance_train.min()\n",
    "bins = np.arange(distance_train_min, distance_train_max, 4)\n",
    "\n",
    "hist_dist_train = []\n",
    "for d in distance_train:\n",
    "    hist_d = np.histogram(d,bins=bins)[0]/np.histogram(d,bins=bins)[0].sum()\n",
    "    hist_dist_train.append(hist_d)\n",
    "\n",
    "hist_dist_train = np.array(hist_dist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6d83db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24489796, 0.24489796, 0.34693878, 0.16326531],\n",
       "       [0.53061224, 0.46938776, 0.        , 0.        ],\n",
       "       [0.26530612, 0.24489796, 0.30612245, 0.18367347],\n",
       "       ...,\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.26530612, 0.20408163, 0.2244898 , 0.30612245]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_dist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3c339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "845f2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute normalized histogram of speed difference\n",
    "speed_receivers_train = np.sqrt((velocity_receivers_train**2).sum(-1))\n",
    "speed_senders_train = np.sqrt((velocity_senders_train**2).sum(-1))\n",
    "\n",
    "diff_speed_train = np.abs(speed_receivers_train-speed_senders_train)\n",
    "diff_speed_train = diff_speed_train.reshape((-1, diff_speed_train.shape[-1]))\n",
    "\n",
    "diff_speed_train_max = diff_speed_train.max()\n",
    "diff_speed_train_min = diff_speed_train.min()\n",
    "bins = np.arange(diff_speed_train_min, diff_speed_train_max, 0.2)\n",
    "\n",
    "hist_diff_speed_train = []\n",
    "for d in diff_speed_train:\n",
    "    hist_d = np.histogram(d,bins=bins)[0]/np.histogram(d,bins=bins)[0].sum()\n",
    "    hist_diff_speed_train.append(hist_d)\n",
    "    \n",
    "hist_diff_speed_train = np.array(hist_diff_speed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "573e7fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93877551, 0.06122449, 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.83673469, 0.16326531, 0.        , 0.        , 0.        ],\n",
       "       ...,\n",
       "       [0.81632653, 0.18367347, 0.        , 0.        , 0.        ],\n",
       "       [0.30612245, 0.55102041, 0.14285714, 0.        , 0.        ],\n",
       "       [0.79591837, 0.20408163, 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_diff_speed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42a064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c28dc051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute normalized histogram of absolute difference in direction\n",
    "velocity_receivers_train\n",
    "\n",
    "tans_receivers = velocity_receivers_train[:,:,:,1]/velocity_receivers_train[:,:,:,0]\n",
    "directions_receivers = np.arctan(tans_receivers)\n",
    "\n",
    "tans_senders = velocity_senders_train[:,:,:,1]/velocity_senders_train[:,:,:,0]\n",
    "directions_senders = np.arctan(tans_senders)\n",
    "\n",
    "diff_directions = np.abs(directions_senders-directions_receivers)\n",
    "\n",
    "#create histogram\n",
    "bins = np.arange(0, np.pi+0.25*np.pi, 0.25*np.pi)\n",
    "hist_diff_dire_train = []\n",
    "\n",
    "diff_directions = diff_directions.reshape((-1, diff_directions.shape[-1]))\n",
    "\n",
    "for d in diff_directions:\n",
    "    hist_d = np.histogram(d,bins=bins)[0]/np.histogram(d,bins=bins)[0].sum()\n",
    "    hist_diff_dire_train.append(hist_d)\n",
    "    \n",
    "hist_diff_dire_train = np.array(hist_diff_dire_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f61855fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3877551 , 0.26530612, 0.34693878, 0.        ],\n",
       "       [0.85714286, 0.14285714, 0.        , 0.        ],\n",
       "       [0.28571429, 0.40816327, 0.30612245, 0.        ],\n",
       "       ...,\n",
       "       [0.75510204, 0.14285714, 0.10204082, 0.        ],\n",
       "       [0.34693878, 0.55102041, 0.10204082, 0.        ],\n",
       "       [0.34693878, 0.44897959, 0.20408163, 0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_diff_dire_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c5397f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08a21b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized histogram of absolute difference in velocity direction\n",
    "#and relative position\n",
    "\n",
    "diff_locations_train = location_senders_train-location_receivers_train\n",
    "diff_locations_train_tans = diff_locations_train[:,:,:,1]/diff_locations_train[:,:,:,0]\n",
    "relative_positions = np.arctan(diff_locations_train_tans)\n",
    "\n",
    "diff_velocities_train = velocity_senders_train-velocity_receivers_train\n",
    "diff_velocities_train_tans = diff_velocities_train[:,:,:,1]/diff_velocities_train[:,:,:,0]\n",
    "velocity_dires = np.arctan(diff_velocities_train_tans)\n",
    "\n",
    "diff_vel_loc = np.abs(relative_positions-velocity_dires)\n",
    "\n",
    "#create histogram\n",
    "bins = np.arange(0, np.pi+0.25*np.pi,0.25*np.pi)\n",
    "hist_diff_vel_loc_train = []\n",
    "diff_vel_loc = diff_vel_loc.reshape((-1, diff_vel_loc.shape[-1]))\n",
    "\n",
    "for d in diff_vel_loc:\n",
    "    hist_d = np.histogram(d,bins=bins)[0]/np.histogram(d,bins=bins)[0].sum()\n",
    "    hist_diff_vel_loc_train.append(hist_d)\n",
    "    \n",
    "hist_diff_vel_loc_train = np.array(hist_diff_vel_loc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70023d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95918367, 0.02040816, 0.02040816, 0.        ],\n",
       "       [0.97959184, 0.02040816, 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ],\n",
       "       ...,\n",
       "       [0.57142857, 0.36734694, 0.06122449, 0.        ],\n",
       "       [0.        , 0.81632653, 0.18367347, 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_diff_vel_loc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72417037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate features\n",
    "\n",
    "hist_feat_train = np.concatenate([hist_dist_train, hist_diff_speed_train,\n",
    "                                 hist_diff_dire_train, hist_diff_vel_loc_train], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f386f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 17)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_feat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a06007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels\n",
    "labels_train = edges_train.flatten()\n",
    "labels_train[labels_train==0]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "564f76d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e201e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65b3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff227c37",
   "metadata": {},
   "source": [
    "## Feature Engineering on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab3a5479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5, 196)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_test_re = feat_test.reshape((feat_test.shape[0], feat_test.shape[1],-1))\n",
    "feat_test_re.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82a01f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "senders_test = np.matmul(rel_send, feat_test_re)\n",
    "receivers_test = np.matmul(rel_rec, feat_test_re)\n",
    "senders_test = senders_test.reshape((senders_test.shape[0], senders_test.shape[1],feat_test.shape[2],feat_test.shape[-1]))\n",
    "receivers_test = receivers_test.reshape((receivers_test.shape[0],receivers_test.shape[1],feat_test.shape[2],feat_test.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31c0e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_senders_test = senders_test[:,:,:,2:]\n",
    "velocity_receivers_test = receivers_test[:,:,:,2:]\n",
    "location_senders_test = senders_test[:,:,:,:2]\n",
    "location_receivers_test = receivers_test[:,:,:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d3a5e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Normalized distance histogram\n",
    "distance_test = location_senders_test-location_receivers_test\n",
    "distance_test = distance_test**2\n",
    "distance_test = distance_test.sum(-1)\n",
    "distance_test = np.sqrt(distance_test)\n",
    "distance_test = distance_test.reshape((-1, distance_test.shape[-1]))\n",
    "\n",
    "#use training information\n",
    "bins = np.arange(distance_train_min, distance_train_max, 4)\n",
    "\n",
    "hist_dist_test = []\n",
    "for d in distance_test:\n",
    "    hist_d = np.histogram(d,bins=bins)[0]/np.histogram(d,bins=bins)[0].sum()\n",
    "    hist_dist_test.append(hist_d)\n",
    "\n",
    "hist_dist_test = np.array(hist_dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "422d5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute normalized histogram of speed difference\n",
    "speed_receivers_test = np.sqrt((velocity_receivers_test**2).sum(-1))\n",
    "speed_senders_test = np.sqrt((velocity_senders_test**2).sum(-1))\n",
    "\n",
    "diff_speed_test = np.abs(speed_receivers_test-speed_senders_test)\n",
    "diff_speed_test = diff_speed_test.reshape((-1, diff_speed_test.shape[-1]))\n",
    "\n",
    "\n",
    "bins = np.arange(diff_speed_train_min, diff_speed_train_max, 0.2)\n",
    "\n",
    "hist_diff_speed_test = []\n",
    "for d in diff_speed_test:\n",
    "    hist_d = np.histogram(d,bins=bins)[0]/np.histogram(d,bins=bins)[0].sum()\n",
    "    hist_diff_speed_test.append(hist_d)\n",
    "    \n",
    "hist_diff_speed_test = np.array(hist_diff_speed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2448680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40816327, 0.59183673, 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_diff_speed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aeeece5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute normalized histogram of absolute difference in direction\n",
    "velocity_receivers_test\n",
    "\n",
    "tans_receivers = velocity_receivers_test[:,:,:,1]/velocity_receivers_test[:,:,:,0]\n",
    "directions_receivers = np.arctan(tans_receivers)\n",
    "\n",
    "tans_senders = velocity_senders_test[:,:,:,1]/velocity_senders_test[:,:,:,0]\n",
    "directions_senders = np.arctan(tans_senders)\n",
    "\n",
    "diff_directions = np.abs(directions_senders-directions_receivers)\n",
    "\n",
    "#create histogram\n",
    "bins = np.arange(0, np.pi+0.25*np.pi, 0.25*np.pi)\n",
    "hist_diff_dire_test = []\n",
    "\n",
    "diff_directions = diff_directions.reshape((-1, diff_directions.shape[-1]))\n",
    "\n",
    "for d in diff_directions:\n",
    "    hist_d = np.histogram(d,bins=bins)[0]/np.histogram(d,bins=bins)[0].sum()\n",
    "    hist_diff_dire_test.append(hist_d)\n",
    "    \n",
    "hist_diff_dire_test = np.array(hist_diff_dire_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f3b36ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36734694, 0.63265306, 0.        , 0.        ],\n",
       "       [0.        , 0.57142857, 0.42857143, 0.        ],\n",
       "       [0.63265306, 0.36734694, 0.        , 0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.6122449 , 0.3877551 ],\n",
       "       [0.        , 0.16326531, 0.79591837, 0.04081633],\n",
       "       [0.        , 0.        , 0.6122449 , 0.3877551 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_diff_dire_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2140f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized histogram of absolute difference in velocity direction\n",
    "#and relative position\n",
    "\n",
    "diff_locations_test = location_senders_test-location_receivers_test\n",
    "diff_locations_test_tans = diff_locations_test[:,:,:,1]/diff_locations_test[:,:,:,0]\n",
    "relative_positions = np.arctan(diff_locations_test_tans)\n",
    "\n",
    "diff_velocities_test = velocity_senders_test-velocity_receivers_test\n",
    "diff_velocities_test_tans = diff_velocities_test[:,:,:,1]/diff_velocities_test[:,:,:,0]\n",
    "velocity_dires = np.arctan(diff_velocities_test_tans)\n",
    "\n",
    "diff_vel_loc = np.abs(relative_positions-velocity_dires)\n",
    "\n",
    "#create histogram\n",
    "bins = np.arange(0, np.pi+0.25*np.pi,0.25*np.pi)\n",
    "hist_diff_vel_loc_test = []\n",
    "diff_vel_loc = diff_vel_loc.reshape((-1, diff_vel_loc.shape[-1]))\n",
    "\n",
    "for d in diff_vel_loc:\n",
    "    hist_d = np.histogram(d,bins=bins)[0]/np.histogram(d,bins=bins)[0].sum()\n",
    "    hist_diff_vel_loc_test.append(hist_d)\n",
    "    \n",
    "hist_diff_vel_loc_test = np.array(hist_diff_vel_loc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "226daafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_diff_vel_loc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "241e58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate test features\n",
    "\n",
    "hist_feat_test = np.concatenate([hist_dist_test, hist_diff_speed_test,\n",
    "                                 hist_diff_dire_test, hist_diff_vel_loc_test], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa831222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 17)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_feat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a55843be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert labels\n",
    "labels_test = edges_test.flatten()\n",
    "labels_test[labels_test==0]=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0b4455d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac5042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "842cdd89",
   "metadata": {},
   "source": [
    "## Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a196b87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training model\n",
    "clf = SVC(gamma=\"auto\")\n",
    "clf.fit(hist_feat_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89f0f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_edges = clf.predict(hist_feat_test)\n",
    "predicted_edges = predicted_edges.reshape((-1, num_atoms*(num_atoms-1)))\n",
    "predicted_edges[predicted_edges==-1]=0\n",
    "\n",
    "#build diagonal embeddings, shape: [batch_size, n_edges, n_edges]\n",
    "\n",
    "predicted_edges_diag = []\n",
    "for edge in predicted_edges:\n",
    "    edge_diag = np.diag(edge)\n",
    "    predicted_edges_diag.append(edge_diag)\n",
    "    \n",
    "predicted_edges_diag = np.array(predicted_edges_diag)\n",
    "\n",
    "predicted_relations = np.matmul(rel_send.T, np.matmul(predicted_edges_diag, rel_rec))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e09d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create relation labels\n",
    "\n",
    "label_edges_diag = []\n",
    "for edge in edges_test:\n",
    "    edge_diag = np.diag(edge)\n",
    "    label_edges_diag.append(edge_diag)\n",
    "    \n",
    "label_edges_diag = np.array(label_edges_diag)\n",
    "\n",
    "label_relations = np.matmul(rel_send.T, np.matmul(label_edges_diag, rel_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "64809a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model with Group-Mitre\n",
    "\n",
    "from sknetwork.topology import get_connected_components\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5f7ef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall:  0.9116666666666666\n",
      "Average Precision:  0.8569166666666667\n",
      "Average F1:  0.876547619047619\n"
     ]
    }
   ],
   "source": [
    "precision_test = []\n",
    "recall_test = []\n",
    "F1_test = []\n",
    "\n",
    "for i in range(len(label_relations)):\n",
    "    label = label_relations[i]\n",
    "    pred = predicted_relations[i]\n",
    "    if label.sum()==0:\n",
    "        label_con = np.arange(num_atoms)\n",
    "    else:\n",
    "        label_con = get_connected_components(label)\n",
    "    if pred.sum()==0:\n",
    "        pred_con = np.arange(num_atoms)\n",
    "    else:\n",
    "        pred_con = get_connected_components(pred)\n",
    "        \n",
    "    recall, precision, F1 = compute_groupMitre_labels(label_con, pred_con)\n",
    "    \n",
    "    recall_test.append(recall)\n",
    "    precision_test.append(precision)\n",
    "    F1_test.append(F1)\n",
    "    \n",
    "print(\"Average Recall: \", np.mean(recall_test))\n",
    "print(\"Average Precision: \", np.mean(precision_test))\n",
    "print(\"Average F1: \", np.mean(F1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c141c558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce34f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
